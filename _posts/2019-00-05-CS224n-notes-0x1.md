---
layout:     post
title:      "cs224n lecture2"
subtitle:   " \"word2vec basic concept\""
date:       2019-09-05 20:00:00
author:     "Rumia"
catalog: true
category: blog
tags:
    - nlp
    - cs224n
---



>  终于是花了三四天时间断断续续看完了cs224n lecture2，难度真的是指数型上升。



## Basic Concept

### word embedding

- 什么是词嵌入？

  自然语言不像图像信息一样，自然语言的基本单位是文字，在英文中是word，中文中是字，他们都是有具体意义的抽象表示，而所谓图像处理，处理的本身就是图像信号，图像本身在采集或者创建好就是以数字形式存储在计算中。但是，重点来了，要使用统计的方法处理自然语言，就必须以一定的形式量化编码词，说简单一点，就是把符号形式的文字转化成数值，或者说嵌入到一个数学空间里，建立一个从文字到数学空间的映射。也就是所谓的词嵌入，而这里要将到的 [**word2vec**](https://en.wikipedia.org/wiki/Word2vec)便是常用的词嵌入的一种。**也就是说，词嵌入就是把词进行了数值化的表示。**

- 如何进行词嵌入？

  **word2vec** 是一种典型的词嵌入方法，使用一个全连接网络（输入层，隐含层，输出层）得到一个训练好的可以表征词向量的模型。

### wrod2vec的一些具体含义

- 比较直观的理解

  比较通俗的解释方法是，我们把一个词转化成所谓向量，也就是把这个词进行了量化表示，一个比较直观的例子，颜色。我们都知道，颜色在计算机中通常使用rgb，也就是红绿蓝三原色进行编码，很自然的可以通过一个三维向量，比如蓝色（0，0，255），这就是一个经过编码的空间向量，但如果我们不知道所谓的蓝色的向量化表示呢？